{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bdba9e4-e87f-48c6-9807-c776c5e6aaea",
   "metadata": {},
   "source": [
    "# 1. Taxonomic Profiling and Data Wrangling\n",
    "\n",
    "## Objective\n",
    "The goal of this notebook is to process the raw output reports generated by `Kraken2` for all 120 samples (60 T2D / 60 Control). We aim to consolidate the individual read counts into a single, comprehensive Taxa x Samples matrix (Abundance Matrix), which is the necessary input for statistical analysis and visualization of gut dysbiosis.\n",
    "\n",
    "## Methodology\n",
    "The process involves reading 120 individual `.report` files, filtering only for biologically meaningful ranks (Phylum, Class, Genus, Species), and joining the results using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b0a0d-e787-4d40-9084-9fdad8e9f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Imports and Configuration\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# Configuration: Path to Kraken2 reports directory\n",
    "REPORTS_DIR = 'results/kraken'\n",
    "\n",
    "# Standard Kraken2 report column names\n",
    "# Columns: % of reads | Number of reads | Reads rooted at this taxon | Rank code | NCBI TaxID | Scientific Name\n",
    "KRAKEN_COLS = ['percent', 'reads', 'reads_taxo', 'rank', 'taxid', 'name']\n",
    "\n",
    "print(\"‚úÖ Cell 1 Complete: Libraries imported and configuration set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc199f06-3202-4c2e-bbfb-a748335b418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define Data Parsing Function\n",
    "def load_kraken_report(file_path):\n",
    "    \"\"\"\n",
    "    Reads a single Kraken2 report file, filters for Species level, \n",
    "    and returns a clean pandas Series with read counts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Read the report file (Tab-separated)\n",
    "        # We use latin-1 encoding to handle special characters in scientific names\n",
    "        df = pd.read_csv(file_path, sep='\\t', header=None, names=KRAKEN_COLS, encoding='latin-1')\n",
    "        \n",
    "        # 2. Extract Sample ID from the filename (e.g., 'SRR123.report' -> 'SRR123')\n",
    "        sample_id = os.path.basename(file_path).replace('.report', '')\n",
    "        \n",
    "        # 3. Filter: Keep ONLY Species level ('S')\n",
    "        # This prevents double-counting reads at different taxonomic levels\n",
    "        df_filtered = df[df['rank'] == 'S'].copy()\n",
    "        \n",
    "        # 4. Data Cleaning: Strip whitespace from names\n",
    "        df_filtered['name'] = df_filtered['name'].str.strip()\n",
    "        \n",
    "        # 5. Select relevant columns and rename 'reads' to the Sample ID\n",
    "        # We use 'reads' (direct count assigned to this taxon)\n",
    "        df_final = df_filtered[['name', 'reads']].rename(columns={'reads': sample_id})\n",
    "        \n",
    "        # 6. Set scientific name as index for easy merging later\n",
    "        return df_final.set_index('name')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Cell 2 Complete: Parsing function defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593a99a-d58c-44e5-8a0b-222c49286b20",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Integration\n",
    "\n",
    "In this step, we locate all Kraken2 report files generated by the upstream pipeline. We iterate through each file, extracting species-level abundance data using the parsing function defined above. Finally, we merge these individual datasets into a single comprehensive abundance matrix ($N \\times M$), where $N$ represents the number of unique species identified and $M$ represents the number of samples (120).\n",
    "\n",
    "Missing values (species present in some samples but not others) are filled with `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01b99f-74bf-4897-93e0-ded81881b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load Reports and Build Abundance Matrix\n",
    "\n",
    "# 1. Locate all report files\n",
    "report_files = glob.glob(os.path.join(REPORTS_DIR, '*.report'))\n",
    "print(f\"üìÇ Found {len(report_files)} Kraken2 report files.\")\n",
    "\n",
    "# 2. Iterate and Load\n",
    "print(\"‚è≥ Loading and merging files... Please wait.\")\n",
    "\n",
    "all_dataframes = []\n",
    "for file in report_files:\n",
    "    # Use the function defined in Cell 2\n",
    "    df = load_kraken_report(file)\n",
    "    \n",
    "    if df is not None:\n",
    "        all_dataframes.append(df)\n",
    "\n",
    "# 3. Concatenate into a Single Matrix\n",
    "if all_dataframes:\n",
    "    # axis=1: Merge by columns (samples side-by-side)\n",
    "    # join='outer': Keep all species found in any sample\n",
    "    # fillna(0): If a species is missing in a sample, abundance is 0\n",
    "    final_tax_table = pd.concat(all_dataframes, axis=1, join='outer').fillna(0)\n",
    "    \n",
    "    print(\"\\n=== Matrix Generation Complete ===\")\n",
    "    print(f\"‚úÖ Successfully created abundance matrix.\")\n",
    "    print(f\"üìä Dimensions: {final_tax_table.shape[0]} Species (Rows) x {final_tax_table.shape[1]} Samples (Columns)\")\n",
    "    \n",
    "    # Preview the first few rows\n",
    "    display(final_tax_table.head())\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Error: No dataframes loaded. Please check the file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82321ff-9b19-478c-8e2c-7520a88a4940",
   "metadata": {},
   "source": [
    "## 3. Metadata Integration (Automatic Fetch)\n",
    "\n",
    "To perform comparative analysis, we need to map each Run ID (e.g., `SRR...`) to its experimental group (Type 2 Diabetes vs. Healthy Control).\n",
    "\n",
    "Since the local metadata file is incomplete, we fetch the official study design directly from the **European Nucleotide Archive (ENA)** API for project **PRJNA422434**. We parse the sample aliases to classify them:\n",
    "* **Case:** Samples labeled with 'T2D' or 'Case'.\n",
    "* **Control:** All other samples (Healthy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f88d67-2ce0-4e09-b98c-eee55da270e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fetch Metadata and Map Groups (Fixed Logic)\n",
    "\n",
    "# 1. Define Project ID\n",
    "PROJECT_ID = \"PRJNA422434\"\n",
    "print(f\"üåç Fetching official metadata for {PROJECT_ID} from ENA API...\")\n",
    "\n",
    "# 2. Construct API URL\n",
    "url = f\"https://www.ebi.ac.uk/ena/portal/api/filereport?accession={PROJECT_ID}&result=read_run&fields=run_accession,sample_alias,sample_title&format=tsv\"\n",
    "\n",
    "try:\n",
    "    # 3. Download and Parse Metadata\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    meta_online = pd.read_csv(io.StringIO(response.content.decode('utf-8')), sep='\\t')\n",
    "    \n",
    "    print(\"‚úÖ Metadata downloaded successfully.\")\n",
    "    \n",
    "    # 4. Create Mapping Dictionary (Run ID -> Group)\n",
    "    run_to_group = {}\n",
    "    \n",
    "    for index, row in meta_online.iterrows():\n",
    "        run_id = row['run_accession']\n",
    "        full_info = str(row['sample_alias'])\n",
    "        \n",
    "        # --- The Fixed Logic ---\n",
    "        # If 'T2D' is in the alias -> Case\n",
    "        # Everything else -> Control\n",
    "        if 'T2D' in full_info:\n",
    "            run_to_group[run_id] = 'T2D'\n",
    "        else:\n",
    "            run_to_group[run_id] = 'Control'\n",
    "            \n",
    "    # 5. Apply Mapping to our Matrix Columns\n",
    "    # We map only the samples that exist in our final_tax_table\n",
    "    metadata = pd.DataFrame(index=final_tax_table.columns)\n",
    "    metadata['Group'] = metadata.index.map(run_to_group)\n",
    "    \n",
    "    # 6. Verify Distribution\n",
    "    print(\"\\n=== Final Sample Distribution ===\")\n",
    "    print(metadata['Group'].value_counts())\n",
    "    \n",
    "    # Check balance\n",
    "    t2d_count = metadata[metadata['Group'] == 'T2D'].shape[0]\n",
    "    control_count = metadata[metadata['Group'] == 'Control'].shape[0]\n",
    "    \n",
    "    if t2d_count > 0 and control_count > 0:\n",
    "        print(\"\\n‚úÖ Metadata mapping successful: Groups are identified correctly!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Warning: Still seeing imbalance. Please check the output.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error fetching metadata: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe2b74-5a47-4589-842e-d57559ffa3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Visualization and Saving Results\n",
    "\n",
    "# 1. Calculate Top 10 Most Abundant Species\n",
    "# Sum reads across all samples, sort descending, and take top 10\n",
    "top_10_species = final_tax_table.sum(axis=1).sort_values(ascending=False).head(10)\n",
    "\n",
    "# 2. Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=top_10_species.values, y=top_10_species.index, palette=\"viridis\")\n",
    "\n",
    "# Styling the plot\n",
    "plt.title(\"Top 10 Most Abundant Species (Gut Microbiome - 120 Samples)\", fontsize=16)\n",
    "plt.xlabel(\"Total Reads count\", fontsize=14)\n",
    "plt.ylabel(\"Species\", fontsize=14)\n",
    "\n",
    "# 3. Save the Plot\n",
    "plt.savefig(\"top10_species_abundance.png\", dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Plot saved as 'top10_species_abundance.png'\")\n",
    "\n",
    "# 4. Save the Data for downstream analysis (e.g., in R)\n",
    "final_tax_table.to_csv(\"abundance_matrix_species.csv\")\n",
    "metadata.to_csv(\"metadata_mapped.csv\")\n",
    "print(\"‚úÖ Data saved: 'abundance_matrix_species.csv' and 'metadata_mapped.csv'\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af6637-5791-452a-b3b2-f2fe87a2939a",
   "metadata": {},
   "source": [
    "# 4. Conclusion & Next Steps\n",
    "\n",
    "## Scientific Observations based on Top 10 Taxa\n",
    "1.  **Dominance of *Segatella copri* (*Prevotella copri*):** The abundance plot reveals that *Segatella copri* is the most abundant species across the cohort. Given its known association with insulin resistance and branched-chain amino acid biosynthesis, this is a strong candidate biomarker for T2D in our dataset.\n",
    "2.  **Bacteroidetes Prevalence:** The top ranks are heavily populated by *Phocaeicola* and *Bacteroides* species (*P. vulgatus*, *B. uniformis*), confirming that the gut microbiome in this cohort is driven by the Bacteroidetes phylum.\n",
    "3.  **Presence of Beneficial Taxa:** *Faecalibacterium prausnitzii*, a key butyrate producer known to be depleted in T2D, appears in the top 10. Future statistical analysis (differential abundance) will determine if its levels are significantly lower in the Case group compared to Controls.\n",
    "\n",
    "## Future Directions (Functional Analysis)\n",
    "Having established the taxonomic landscape (\"Who is there\"), we observe a mix of potential pathogens (*P. copri*) and beneficial bacteria (*F. prausnitzii*). The next step is to investigate the metabolic implications:\n",
    "* *Functional Profiling:* Do T2D patients show a reduction in genes related to **Butyrate Production**?\n",
    "* *Pathway Analysis:* Is there an enrichment of **Inflammation-related pathways** in samples dominated by *Segatella*?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
